{"test_name": "cross_entropy_loss", "response_0": "from Compiler.types import sfix\n\ndef cross_entropy(y):\n    # Initialize the result as a secret fixed-point zero.\n    result = sfix(0)\n    # Iterate through each secret value in the list y.\n    for yi in y:\n        # Multiply yi by its logarithm (using the sfix logarithm approximation).\n        # Note: In MP-SPDZ, the logarithm is computed using the built-in method log().\n        result += yi * yi.log()\n    # Return the negative sum which corresponds to the cross-entropy loss.\n    return -result\n", "response_1": "from Compiler.types import sfix\n\ndef cross_entropy(y):\n    \"\"\"\n    Compute the cross-entropy loss for a secure vector y.\n    Here, y is a list (or other iterable) of sfix numbers.\n    \"\"\"\n    total = sfix(0)\n    for value in y:\n        # sfix.log(value) computes the secure logarithm approximation.\n        total += value * sfix.log(value)\n    return -total\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_square_sqrt", "response_0": "from Compiler.library import sqrt\nfrom Compiler.types import sfix\n\ndef compute_RMSD(array):\n    # Compute the mean of the array.\n    n = len(array)\n    sum_val = sfix(0)\n    for a in array:\n        sum_val += a\n    mean = sum_val / sfix(n)\n    \n    # Compute the sum of squared deviations.\n    square_sum = sfix(0)\n    for a in array:\n        deviation = a - mean\n        square = deviation * deviation\n        square_sum += square\n    square_mean = square_sum / sfix(n)\n    \n    # Compute the square root of the mean squares.\n    rmsd = sqrt(square_mean)\n    return rmsd\n", "response_1": "from Compiler.library import sqrt\nfrom Compiler.types import sfix\n\ndef compute_RMSD(array):\n    # Compute the mean of the array\n    n = len(array)\n    total = sfix(0)\n    for i in range(n):\n        total += array[i]\n    mean = total / sfix(n)\n    \n    # Compute the sum of squared deviations\n    sq_sum = sfix(0)\n    for i in range(n):\n        deviation = array[i] - mean\n        sq_sum += deviation * deviation\n        \n    # Compute the mean of squared deviations and take its square root\n    square_mean = sq_sum / sfix(n)\n    rmsd = sqrt(square_mean)\n    return rmsd\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "logsumexp", "response_0": "from Compiler.library import if_else, exp, log\n\n# Define a secure max function over a list of secret shared numbers\ndef secure_max(arr):\n    m = arr[0]\n    for x in arr[1:]:\n        # if x > m then choose x else keep m\n        m = if_else(x > m, x, m)\n    return m\n\n# Secure logsumexp computation\ndef logsumexp(log_probs):\n    # Compute maximum in a secure manner\n    _max = secure_max(log_probs)\n    \n    # Compute the sum of exponentials of the differences\n    exp_sum = 0\n    for x in log_probs:\n        ds = x - _max\n        exp_sum = exp_sum + exp(ds)\n    \n    # Return the final result _max + log(exp_sum)\n    return _max + log(exp_sum)\n", "response_1": "from Compiler.Numeric import sfix\n\ndef logsumexp(log_probs):\n    \"\"\"\n    Compute the logsumexp of a list of secret fixed-point values.\n    \"\"\"\n    # Compute maximum in a secure way.\n    _max = log_probs[0]\n    for lp in log_probs[1:]:\n        # The comparison '>' returns a secret bit.\n        is_gt = lp > _max\n        # Securely update the maximum.\n        _max = is_gt * lp + (1 - is_gt) * _max\n\n    exp_sum = sfix(0)\n    for lp in log_probs:\n        d = lp - _max\n        # Compute the secure exponential (assuming sfix supports .exp()).\n        exp_sum += d.exp()\n        \n    # Compute log(exp_sum) securely (assuming sfix supports .log()).\n    return _max + exp_sum.log()\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "binary_cross_entropy_loss", "response_0": "from Compiler.types import sfix\nfrom Compiler.library import math_log2\n\ndef binary_cross_entropy(y_hat, y):\n    \"\"\"\n    Compute the binary cross-entropy loss.\n    Assumes y_hat and y are lists of sfix values.\n    \"\"\"\n    n = len(y_hat)\n    \n    # Replace any 0 or 1 in y_hat by a small margin\n    for i in range(n):\n        # Note: Using direct equality on sfix values assumes that y_hat[i] is public or that equality is determinable.\n        if y_hat[i] == sfix(0):\n            y_hat[i] = sfix(0.001)\n        elif y_hat[i] == sfix(1):\n            y_hat[i] = sfix(1 - 0.001)\n    \n    total = sfix(0)\n    for i in range(n):\n        # Compute y*log2(y_hat) and (1-y)*log2(1-y_hat) using secure logarithm\n        term1 = y[i] * math_log2(y_hat[i])\n        term2 = (sfix(1) - y[i]) * math_log2(sfix(1) - y_hat[i])\n        total += term1 + term2\n    \n    # Compute the mean of the loss terms\n    mean_val = total / sfix(n)\n    loss = - mean_val\n    return loss\n", "response_1": "# MP-SPDZ version of binary cross entropy using sfix arithmetic\n# (if y_hat is assumed to be secret, one may replace the if/elif with if_else constructs.)\n\nfrom Compiler.types import sfix\n\ndef binary_cross_entropy(y_hat, y):\n    \"\"\"\n    Compute the binary cross-entropy loss\n    Input: y_hat, y are lists of sfix values.\n    \"\"\"\n    n = len(y_hat)\n    total_loss = sfix(0)\n    for i in range(n):\n        # Replace exact 0 and 1 values for numerical stability:\n        # Note: if y_hat[i] is a secret value one should use a secure if_else.\n        if y_hat[i] == sfix(0):\n            cur_y_hat = sfix(0.001)\n        elif y_hat[i] == sfix(1):\n            cur_y_hat = sfix(1) - sfix(0.001)\n        else:\n            cur_y_hat = y_hat[i]\n        # Compute log2 for the current prediction, and for 1 - prediction.\n        # (The log2() method is available on sfix values.)\n        log_y_hat = cur_y_hat.log2()\n        one_minus_cur_y_hat = sfix(1) - cur_y_hat\n        log_one_minus_y_hat = one_minus_cur_y_hat.log2()\n        # Compute the loss for this data point: \n        #     loss_element = -[y*log2(cur_y_hat) + (1-y)*log2(1-cur_y_hat)]\n        loss_element = -( y[i] * log_y_hat + (sfix(1) - y[i]) * log_one_minus_y_hat )\n        total_loss += loss_element\n    # Return the mean loss over all inputs.\n    return total_loss / sfix(n)\n\n# You can call binary_cross_entropy with two arrays of type sfix of the same length.\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_less_equal", "response_0": "from Compiler.types import sint\n\ndef compute_less_equal(arrayA, arrayB):\n    # This function calculates the element\u2010wise comparison: whether arrayA <= arrayB.\n    result = []\n    for a, b in zip(arrayA, arrayB):\n        # In MP-SPDZ, the operator \"<\" applied to secret integers yields a secret bit.\n        # Since a \u2264 b is equivalent to not (b < a), we can compute it as:\n        result.append(1 - (b < a))\n    return result\n", "response_1": "from Compiler.types import sint, sbit\nfrom Compiler.compare import less_than\n\ndef compute_less_equal(arrayA, arrayB):\n    \"\"\"\n    This function calculates the element-wise comparison, i.e. whether arrayA is less than or equal to arrayB.\n    The comparison (a \u2264 b) is evaluated as: 1 - (b < a).\n    \"\"\"\n    n = len(arrayA)\n    result = []\n    for i in range(n):\n        # Compute secure comparison: if arrayB[i] < arrayA[i] then this returns a secure bit (1 if true, 0 otherwise)\n        cmp_result = less_than(arrayB[i], arrayA[i])\n        # Then, a[i] <= b[i] is equivalent to: 1 - cmp_result.\n        # Note that 1 is a public constant and the subtraction is performed in the secret-shared domain.\n        result.append(1 - cmp_result)\n    return result\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "RMS_prop_step", "response_0": "from Compiler.types import sfix\n\ndef RMS_prop_step(grads, layers):\n    # Parameters as secret fixed-point numbers.\n    alpha = sfix(0.5)\n    beta = sfix(1.0)\n    \n    # Initialize s as a list of zeros with the same structure as grads.\n    s = []\n    for grad in grads:\n        # Assume each grad is a list; create a zero list of the same length.\n        s.append([sfix(0) for _ in grad])\n        \n    # Iterate over each layer and update its gradients and parameters.\n    for i in range(len(grads)):\n        # Assuming grads[i], layers[i], and s[i] are lists.\n        for j in range(len(grads[i])):\n            # Update accumulator s: s = beta * s + (1-beta)*grad^2.\n            s[i][j] = beta * s[i][j] + (sfix(1) - beta) * (grads[i][j] * grads[i][j])\n            # Compute updated gradient: alpha * (grad / sqrt(s)).\n            # Note: sfix.sqrt returns an approximate square root.\n            updated_grad = alpha * (grads[i][j] / sfix.sqrt(s[i][j]))\n            # Update the layer: layer = layer + updated_grad.\n            layers[i][j] = layers[i][j] + updated_grad\n    return layers\n", "response_1": "from Compiler.types import sfix\n\ndef RMS_prop_step(grads, layers):\n    # secret fixed point constants\n    alpha = sfix(0.5)\n    beta  = sfix(1.0)\n\n    # initialize s: create a zero\u2013array for each grad of the same length\n    s = []\n    for grad in grads:\n        s.append([sfix(0) for _ in grad])\n\n    # loop over each grad/layer pair to update them element-wise\n    for i in range(len(grads)):\n        grad = grads[i]\n        # temporary new values for s and grad (both being lists)\n        new_s = []\n        new_grad = []\n        # iterate element-wise over the grad array\n        for j in range(len(grad)):\n            # update s using: s[i] = beta*s[i] + (1-beta)*grad^2\n            new_s_val = beta * s[i][j] + (sfix(1) - beta) * (grad[j] * grad[j])\n            new_s.append(new_s_val)\n            # update grad using: grad = alpha * (grad/sqrt(s[i]))\n            # Note: we use the .sqrt() method on sfix variables.\n            new_grad_val = alpha * (grad[j] / new_s_val.sqrt())\n            new_grad.append(new_grad_val)\n        # update s for layer i\n        s[i] = new_s\n        # update layer by adding new_grad element-wise\n        layer = layers[i]\n        updated_layer = []\n        for j in range(len(layer)):\n            updated_layer.append(layer[j] + new_grad[j])\n        layers[i] = updated_layer\n\n    return layers\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "entropy", "response_0": "from Compiler.types import sfix\n\ndef entropy(y):\n    # length of the array, n is public\n    n = len(y)\n    total = sfix(0)\n    \n    # Create a list of unique elements from y\n    seen = []\n    for val in y:\n        if not (val in seen):\n            seen.append(val)\n            \n    # For each unique value, compute its frequency and contribution to entropy\n    for val in seen:\n        count = 0\n        for item in y:\n            if item == val:\n                count += 1\n        # Convert count and n to sfix and compute the ratio\n        ratio = sfix(count) / sfix(n)\n        # Avoid computing log on 0; here count is positive so ratio > 0.\n        # Compute log2(ratio) as ln(ratio) / ln(2)\n        total += -(ratio * (sfix.ln(ratio) / sfix.ln(2)))\n    \n    return total\n", "response_1": "from Compiler.types import sfix\n\ndef entropy(y):\n    # Number of elements in y, used to compute the probabilities\n    n = len(y)\n    # Initialize the entropy accumulation as an sfix variable\n    sum_entropy = sfix(0)\n    # Compute the set of unique values in y (y is assumed public)\n    unique_vals = list(set(y))\n    # For each unique value, count its frequency and update the entropy sum\n    for val in unique_vals:\n        # Count the occurrences of this value in y\n        count_val = y.count(val)\n        # Compute probability as an sfix quotient\n        p = sfix(count_val) / sfix(n)\n        # Compute entropy term: -p * log2(p)\n        # log2(p) = ln(p) / ln(2)\n        sum_entropy += -p * (sfix.ln(p) / sfix.ln(sfix(2)))\n    return sum_entropy\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_exp", "response_0": "from Compiler.types import sfix\nfrom Compiler.library import exp\n\ndef compute_softmax(arr):\n    # Compute the exponentials for each element of the input list.\n    exp_arr = []\n    for x in arr:\n        exp_arr.append(exp(x))\n    \n    # Compute the sum (reduction) of the exponentials.\n    total = sfix(0)\n    for y in exp_arr:\n        total += y\n    \n    # Compute the softmax values by dividing each exponential by the total sum.\n    softmax = []\n    for y in exp_arr:\n        softmax.append(y / total)\n    \n    return softmax\n", "response_1": "from Compiler.types import sfix\nfrom Compiler.library import exp\n\ndef compute_softmax(array):\n    # Compute the exponent of every element,\n    # where \"array\" is assumed to be a list of sfix values.\n    exp_array = []\n    for a in array:\n        exp_array.append(exp(a))\n    \n    # Sum the exponentials.\n    summation = sfix(0)\n    for e in exp_array:\n        summation += e\n\n    # Compute softmax probabilities as exp(a) / summation.\n    softmax = []\n    for e in exp_array:\n        softmax.append(e / summation)\n    \n    return softmax\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "tanh", "response_0": "from Compiler.types import sfix\n\n# Define a constant one as an sfix value.\none = sfix(1)\n\nclass Tanh:\n    # Internal function to compute tanh using the identity:\n    # tanh(x) = (exp(2*x) - 1) / (exp(2*x) + 1)\n    def tanh_func(self, x):\n        exp_2x = (2 * x).exp()\n        return (exp_2x - 1) / (exp_2x + 1)\n\n    # Compute the tanh function element-wise on input z.\n    def fn(self, z):\n        # Check if z is iterable (e.g. a list) or a single sfix value.\n        try:\n            iter(z)\n        except TypeError:\n            # z is a scalar sfix.\n            return self.tanh_func(z)\n        else:\n            # z is a list-like container: compute tanh for each element.\n            return [self.tanh_func(x) for x in z]\n\n    # Evaluate the gradient (first derivative) for the tanh function:\n    # grad = 1 - tanh(x)^2, computed element-wise on input x.\n    def grad(self, x):\n        try:\n            iter(x)\n        except TypeError:\n            # x is a scalar sfix.\n            return one - self.tanh_func(x) * self.tanh_func(x)\n        else:\n            # x is a list-like container: compute gradient for each element.\n            return [one - self.tanh_func(x_item) * self.tanh_func(x_item) for x_item in x]\n", "response_1": "from Compiler.types import sfix\n\nclass Tanh:\n    # Compute tanh using a rational approximation for sfix numbers.\n    def fn(self, z):\n        # z is assumed to be an sfix (or a compatible type)\n        # Approximate tanh(z) as:  z * (27 + z*z) / (27 + 9*z*z)\n        numerator = z * (sfix(27) + z * z)\n        denominator = sfix(27) + sfix(9) * z * z\n        return numerator / denominator\n\n    # Compute the gradient (first derivative) of tanh.\n    def grad(self, x):\n        t = self.fn(x)\n        return sfix(1) - t * t\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_tan", "response_0": "from Compiler.library import math\n\n# Computes the tangent of each element in a given secret list.\ndef compute_tan(array):\n    tan_res = []\n    for x in array:\n        # Compute tangent as sin(x)/cos(x)\n        tan_res.append(math.sin(x) / math.cos(x))\n    return tan_res\n", "response_1": "from Compiler.math import sin, cos\n\ndef compute_tan(array):\n    \"\"\"\n    This function calculates the trigonometric tangent element-wise for an input array.\n    It assumes that the elements of the array are of secret fixed-point type (sfix).\n    \"\"\"\n    tan_res = []\n    for x in array:\n        # Compute tangent as sin(x) / cos(x)\n        tan_val = sin(x) / cos(x)\n        tan_res.append(tan_val)\n    return tan_res\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_greater", "response_0": "from Compiler.types import sint\n\ndef compute_greater(arrayA, arrayB):\n    # Compute element-wise secure comparison (arrayA > arrayB)\n    res = []\n    for a, b in zip(arrayA, arrayB):\n        res.append(a > b)\n    return res\n", "response_1": "from Compiler.types import sint\n\n# This function computes the element-wise comparison of two arrays of type sint.\n# For each index i, it returns a secret bit representing (arrayA[i] > arrayB[i])\ndef compute_greater(arrayA, arrayB):\n    m = len(arrayA)\n    # Optionally one could check that len(arrayA)==len(arrayB)\n    greater_res = [None] * m\n    for i in range(m):\n        # The operator \">\" is overloaded so that a secret comparison is performed.\n        greater_res[i] = arrayA[i] > arrayB[i]\n    return greater_res\n\n# An example main() function, if desired, that sets up sample arrays.\ndef main():\n    # Here one would typically obtain secret inputs from the parties.\n    # For demonstration, we assign dummy values (these values would in practice come from secret inputs).\n    # Make sure that the lengths of the two arrays coincide.\n    # The following input arrays are for illustrative purposes; in practice, they can be provided by the parties securely.\n    arrayA = [sint(5), sint(3), sint(8)]\n    arrayB = [sint(2), sint(4), sint(8)]\n    result = compute_greater(arrayA, arrayB)\n    # The result in each position is a secret bit (1 if corresponding arrayA element is greater than arrayB,\n    # 0 otherwise). The output can be revealed at the end.\n    for res in result:\n        print_ln('%s', res.reveal())\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_maximum", "response_0": "# Note: This program assumes that arrayA and arrayB are lists of secret integers (sint).\ndef compute_maximum(arrayA, arrayB):\n    n = len(arrayA)\n    result = [0] * n\n    for i in range(n):\n        # Compute the secret indicator: 1 if arrayA[i] >= arrayB[i], else 0.\n        flag = arrayA[i] >= arrayB[i]\n        # Compute maximum element in a secret shared fashion.\n        result[i] = flag * arrayA[i] + (1 - flag) * arrayB[i]\n    return result\n", "response_1": "def compute_maximum(arrayA, arrayB):\n    max_array = []\n    for a, b in zip(arrayA, arrayB):\n        # Securely compare: if a < b then condition becomes true.\n        # We then select b if true, otherwise a.\n        max_elem = (a < b).if_else(b, a)\n        max_array.append(max_elem)\n    return max_array\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_log2", "response_0": "from Compiler.types import sfix\nfrom Compiler.library import log, print_ln\n\ndef compute_log2(array):\n    # Compute constant ln(2) to change the base from e to 2.\n    log2_const = log(sfix(2))\n    res = []\n    for x in array:\n        # Compute log_2(x) as ln(x)/ln(2)\n        res.append(log(x) / log2_const)\n    return res\n\ndef main():\n    # Example: Define an array of sfix numbers.\n    arr = [sfix(1.0), sfix(2.0), sfix(4.0), sfix(8.0)]\n    log2_values = compute_log2(arr)\n    print_ln(\"The base-2 logarithms are: %s\", log2_values)\n", "response_1": "from Compiler.types import sfix\n\ndef compute_log2(array):\n    # Compute constant ln(2) in sfix format.\n    log_2 = sfix.log(sfix(2))\n    result = []\n    for x in array:\n        # Compute ln(x) then divide by ln(2) to obtain log\u2082(x)\n        result.append(sfix.log(x) / log_2)\n    return result\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_absolute", "response_0": "def obtain_absolute(array):\n    # This function computes the absolute values of elements in the array.\n    result = []\n    for x in array:\n        # if_else(x < 0, -x, x) returns -x if x < 0, otherwise x.\n        result.append(if_else(x < 0, -x, x))\n    return result\n", "response_1": "# Computes the element\u2013wise absolute values on an array of secret integers.\n# Here, we assume that 'array' is a Python list of type 'sint' (or another secret type)\n# and that the if_else function is available in MP-SPDZ to securely select between values.\n\ndef obtain_absolute(array):\n    res = []\n    for a in array:\n        # Securely select: if a >= 0 then a, else -a.\n        res.append(if_else(a >= 0, a, -a))\n    return res\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_arctan", "response_0": "from Compiler.types import sfix\n\ndef approx_arctan(x, terms=10):\n    # Taylor series: arctan(x) = sum_{i=0}^{terms-1} (-1)^i * x^(2*i+1)/(2*i+1)\n    res = x          # term for i=0 is simply x\n    power = x        # this variable will hold x^(2*i+1)\n    for i in range(1, terms):\n        # Multiply power by x^2 to update: x^(2*i+1)= x^(2*(i-1)+1) * x^2\n        power = power * x * x\n        # Compute current term using (-1)^i / (2*i+1)\n        # Depending on the parity of i, subtract (if odd) or add (if even) the term.\n        if i % 2 == 1:\n            res = res - power / (2 * i + 1)\n        else:\n            res = res + power / (2 * i + 1)\n    return res\n\ndef compute_arctan(array):\n    # Given an array of sfix values, compute the element-wise arctan approximation.\n    result = []\n    for x in array:\n        result.append(approx_arctan(x))\n    return result\n", "response_1": "from Compiler.types import sfix\n\ndef compute_arctan(array):\n    # This function computes a polynomial approximation of arctan(x)\n    # for a secret-shared input x in the interval [-1, 1].\n    res = []\n    # For each secret value x, compute:\n    # arctan(x) \u2248 x \u2212 x\u00b3/3 + x\u2075/5 \u2212 x\u2077/7\n    for x in array:\n        # Compute the required powers of x\n        x_sq = x * x             # x^2\n        term1 = x                # x\n        x_cubed = x * x_sq       # x^3\n        term2 = x_cubed / sfix(3)  # x^3/3\n        x_fifth = x_cubed * x_sq # x^5\n        term3 = x_fifth / sfix(5)  # x^5/5\n        x_seventh = x_fifth * x_sq   # x^7\n        term4 = x_seventh / sfix(7)    # x^7/7\n        # Combine the terms with alternating signs\n        approx = term1 - term2 + term3 - term4\n        res.append(approx)\n    return res\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_log", "response_0": "from Compiler.types import sfix\n\ndef compute_log(arr):\n    # Allocate an output list of the same length as the input array.\n    n = len(arr)\n    result = [None] * n\n    for i in range(n):\n        # Compute the natural logarithm for each secret number,\n        # assuming a built-in ln() method for sfix types.\n        result[i] = arr[i].ln()\n    return result\n", "response_1": "from Compiler.types import sfix\n\ndef secure_ln(x):\n    # Approximate ln(x) using the series: ln(x) = 2*(y + y^3/3 + y^5/5 + ...),\n    # where y = (x-1)/(x+1). Note: this series converges fastest when x is close to 1.\n    y = (x - sfix(1)) / (x + sfix(1))\n    y2 = y * y\n    term = y\n    res = y\n    # We add a fixed number of terms for the approximation (here, for odd exponents 3, 5, 7, 9)\n    for i in [3, 5, 7, 9]:\n        term = term * y2\n        res = res + term / sfix(i)\n    return sfix(2) * res\n\ndef compute_log(sec_arr):\n    # Given a list of sfix numbers, compute their natural logarithm in a secure way.\n    log_list = []\n    for x in sec_arr:\n        log_list.append(secure_ln(x))\n    return log_list\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_not_equal", "response_0": "from Compiler.types import sint\nfrom Compiler.library import is_zero\n\ndef compute_not_equal(arrayA, arrayB):\n    # Assumes that arrayA and arrayB are lists of secret integers (sint)\n    neq = []\n    for i in range(len(arrayA)):\n        # Compute: if arrayA[i] == arrayB[i], then is_zero returns 1\n        # Inverting gives 1 when they are different, 0 otherwise.\n        neq.append(1 - is_zero(arrayA[i] - arrayB[i]))\n    return neq\n\ndef main():\n    # This main function is provided to indicate how the code is structured.\n    # Input and further use of compute_not_equal would be done as per your protocol.\n    pass\n", "response_1": "from Compiler.types import sint\n\ndef compute_not_equal(arrayA, arrayB):\n    # Allocate an output array of the same length as the inputs.\n    neq = [sint(0) for _ in range(len(arrayA))]\n    \n    for i in range(len(arrayA)):\n        # (arrayA[i] == arrayB[i]) yields 1 if equal, else 0.\n        eq = (arrayA[i] == arrayB[i])\n        # Hence, 1 - eq gives 1 if the elements differ, 0 otherwise.\n        neq[i] = 1 - eq\n    return neq\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_equal", "response_0": "# This function computes the element-wise equality of two arrays.\n# For each i, if arrayA[i] equals arrayB[i] then eq[i] = 1, else eq[i] = 0.\ndef compute_equal(arrayA, arrayB):\n    # Create an output list of the same length.\n    eq = [0] * len(arrayA)\n    for i in range(len(arrayA)):\n        # Compute the difference between corresponding elements.\n        diff = arrayA[i] - arrayB[i]\n        # (a-b).is_nonzero() returns 1 if the difference is nonzero,\n        # so 1 - (a-b).is_nonzero() yields 1 exactly when a==b.\n        eq[i] = 1 - diff.is_nonzero()\n    return eq\n\n# Main section can be used to set up inputs and call the function.\n# For example, you might load secret values into arrayA and arrayB,\n# then call equalities = compute_equal(arrayA, arrayB)\n", "response_1": "from Compiler.types import sint\nfrom Compiler.library import eqz\n\ndef compute_equal(arrayA, arrayB):\n    n = len(arrayA)\n    eq = [None] * n\n    for i in range(n):\n        # Compute equality by checking if the difference is zero.\n        eq[i] = eqz(arrayA[i] - arrayB[i])\n    return eq\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_true_divide", "response_0": "from Compiler.types import sfix\n\ndef true_divide(arrayA, arrayB):\n    # Ensure the two arrays have the same length.\n    if len(arrayA) != len(arrayB):\n        print_ln(\"Error: Arrays must have the same length!\")\n        exit(1)\n    \n    result = []\n    for a, b in zip(arrayA, arrayB):\n        result.append(a / b)\n    return result\n", "response_1": "from Compiler.types import sfix\n\ndef true_divide(arrayA, arrayB):\n    # Element-wise division of the two arrays.\n    # Ensure that the arrays have the same length.\n    assert len(arrayA) == len(arrayB)\n    result = []\n    for i in range(len(arrayA)):\n        # Division of sfix types corresponds to true division.\n        result.append(arrayA[i] / arrayB[i])\n    return result\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_greater_equal", "response_0": "from Compiler.types import sint\n\ndef compute_greater_equal(arrayA, arrayB):\n    # Get the length of the arrays\n    n = len(arrayA)\n    # Allocate a result array of secret shares (0/1 values)\n    result = [None] * n\n    for i in range(n):\n        # The secure comparison 'arrayA[i] < arrayB[i]' returns a secret bit,\n        # where 1 denotes True (i.e. arrayA[i] is less than arrayB[i])\n        less = arrayA[i] < arrayB[i]\n        # Therefore, arrayA[i] \u2265 arrayB[i] is equivalent to (1 - less)\n        result[i] = 1 - less\n    return result\n", "response_1": "def compute_greater_equal(arrayA, arrayB):\n    \"\"\"\n    Computes a list of bits such that for each index i, \n    the bit is 1 (as a secret-shared bit) if arrayA[i] >= arrayB[i], and 0 otherwise.\n    \"\"\"\n    # Initialize an empty result list\n    result = []\n    # Iterate over pairs of elements; the overloading of the '>=' operator will call secure routines.\n    for a, b in zip(arrayA, arrayB):\n        result.append(a >= b)\n    return result\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_negative", "response_0": "def negative(arrayA):\n    # This function returns a copy of the input array with each element negated.\n    return [-x for x in arrayA]\n", "response_1": "def negative(arrayA):\n    \"\"\"\n    This function essentially returns a copy of the input array with all its elements being inverse numbers.\n    \"\"\"\n    return [ -elem for elem in arrayA ]\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_power", "response_0": "from Compiler.types import sint\n\ndef secure_pow(x, y):\n    # Computes x raised to the power y.\n    # Here, x is a secret integer and y is a public integer.\n    result = sint(1)\n    for _ in range(y):\n        result = result * x\n    return result\n\ndef power(arrayA, arrayB):\n    \"\"\"\n    Computes element-wise exponentiation for two arrays.\n    arrayA: list of secret integers (sint)\n    arrayB: list of public integers\n    Returns a list where each element is arrayA[i] raised to the power of arrayB[i].\n    \"\"\"\n    result_array = []\n    for a, b in zip(arrayA, arrayB):\n        result_array.append(secure_pow(a, b))\n    return result_array\n", "response_1": "from Compiler.types import sint, cint\n\n# Compute base^exp where exp is assumed to be a known (public) non-negative integer.\ndef secret_power(x, exp):\n    # start with secret 1 of type sint\n    res = sint(1)\n    # convert exp to an integer if not already\n    for i in range(int(exp)):\n        res = res * x\n    return res\n\n# Compute element-wise power for two lists, where each x is a secret and\n# each exponent y is public\ndef power(arrayA, arrayB):\n    n = len(arrayA)\n    out = []\n    for i in range(n):\n        # For each pair, compute x^y using secret_power\n        out.append(secret_power(arrayA[i], arrayB[i]))\n    return out\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_exp2", "response_0": "from Compiler.types import sfix, Array\n\ndef compute_exp2(arr):\n    # ln(2) constant computed to sufficient precision\n    LOG2 = sfix(0.6931471805599453)\n    n = len(arr)\n    res = Array(n, sfix)\n    for i in range(n):\n        # Compute 2**p as exp(p * ln2)\n        res[i] = sfix.exp(arr[i] * LOG2)\n    return res\n", "response_1": "from Compiler.types import sfix\nfrom Compiler.library import exp\n\ndef compute_exp2(array):\n    # ln2 is the natural logarithm of 2.\n    ln2 = sfix(0.69314718056)\n    result = []\n    # Loop over all elements in the public length array.\n    for a in array:\n        # 2**p is computed as exp(ln2 * p)\n        result.append(exp(a * ln2))\n    return result\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "cross_entropy_loss_class", "response_0": "from Compiler.types import sfix\n\ndef cross_entropy_loss(y, y_pred):\n    \"\"\"\n    Compute the cross-entropy (log) loss.\n    The inputs y and y_pred are lists of sfix.\n    \"\"\"\n    total = sfix(0)\n    # Compute ln(2) once so that log2(x) = ln(x) / ln(2)\n    ln2 = sfix(2).ln()\n    for i in range(len(y)):\n        # Compute log2(y_pred[i])\n        log2_val = y_pred[i].ln() / ln2\n        total = total + y[i] * log2_val\n    return -total\n\ndef cross_entropy_grad(y, y_pred):\n    \"\"\"\n    Compute the gradient of the cross entropy loss.\n    Returns a list of sfix.\n    \"\"\"\n    n = sfix(len(y))\n    grad = []\n    for i in range(len(y)):\n        # The gradient is (y_pred - y)/n\n        grad.append((y_pred[i] - y[i]) / n)\n    return grad\n", "response_1": "from Compiler.types import sfix\nfrom Compiler.library import log2\n\nclass CrossEntropy:\n    def loss(self, y, y_pred):\n        # Compute the cross-entropy loss: - sum_i y[i]*log2(y_pred[i])\n        cross_entropy = sfix(0)\n        for i in range(len(y)):\n            # log2 is the approximate logarithm function for sfix values.\n            cross_entropy = cross_entropy - y[i] * log2(y_pred[i])\n        return cross_entropy\n\n    def grad(self, y, y_pred):\n        # Compute the gradient of the loss: (y_pred - y)/n for each element\n        n = len(y)  # n is treated as a public integer\n        gradients = []\n        for i in range(n):\n            gradients.append((y_pred[i] - y[i]) / n)\n        return gradients\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_arccos", "response_0": "from Compiler.types import sfix\nfrom Compiler.library import sqrt\n\n# Approximate arctan(z) using Taylor series expansion.\ndef sfix_arctan(z, num_terms=10):\n    # arctan(z) = z - z^3/3 + z^5/5 - z^7/7 + ...\n    result = z\n    term = z\n    for i in range(1, num_terms):\n        # Compute next term: z^(2*i+1)\n        term = term * z * z\n        coeff = sfix(1.0/(2*i+1))\n        if i % 2 == 1:\n            result = result - term * coeff\n        else:\n            result = result + term * coeff\n    return result\n\n# Compute arccos(x) using the identity:\n#    arccos(x) = 2 * arctan( sqrt((1-x)/(1+x)) )\ndef sfix_arccos(x, num_terms=10):\n    one = sfix(1)\n    pi = sfix(3.141592653589793)\n    # Handle edge cases (assumed public values):\n    if x == one:\n        return sfix(0)\n    elif x == -one:\n        return pi\n    # Compute the square-root term: sqrt((1-x)/(1+x))\n    ratio = (one - x) / (one + x)\n    z = sqrt(ratio)\n    return 2 * sfix_arctan(z, num_terms)\n\n# Element-wise computation of inverse cosine for an array of sfix values.\ndef compute_arccos(array):\n    result = []\n    for x in array:\n        result.append(sfix_arccos(x))\n    return result\n", "response_1": "from Compiler.types import sfix\nfrom Compiler.library import sqrt, atan\n\ndef compute_arccos(array):\n    # Define the constant 1 as a secure fixed-point value.\n    one = sfix(1)\n    result_array = []\n    for x in array:\n        # Compute (1 - x)/(1 + x) securely.\n        fraction = (one - x) / (one + x)\n        # Compute arccos(x) using the identity:\n        # arccos(x) = 2 * atan( sqrt( (1-x)/(1+x) ) )\n        angle = 2 * atan( sqrt(fraction) )\n        result_array.append(angle)\n    return result_array\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "r2_score", "response_0": "from Compiler.types import sfix\n\ndef r2_score(y_hat, y_test):\n    # assume y_hat and y_test are lists of sfix numbers of equal length\n    n = len(y_test)\n    # Compute the mean of y_test.\n    sum_y = sfix(0)\n    for val in y_test:\n        sum_y += val\n    mean_y = sum_y / sfix(n)\n    \n    total_sum_squares = sfix(0)\n    residual_sum_squares = sfix(0)\n    for i in range(n):\n        diff_mean = y_test[i] - mean_y\n        total_sum_squares += diff_mean * diff_mean\n        \n        diff_res = y_test[i] - y_hat[i]\n        residual_sum_squares += diff_res * diff_res\n        \n    # Compute and return the r2 score.\n    return sfix(1) - residual_sum_squares / total_sum_squares\n", "response_1": "from Compiler.types import sfix\n\ndef r2_score(y_hat, y_test):\n    # Compute the mean of y_test\n    n = len(y_test)\n    total = sfix(0)\n    for val in y_test:\n        total = total + val\n    mean = total / sfix(n)\n    \n    # Compute total sum of squares and residual sum of squares\n    total_sum_squares = sfix(0)\n    residual_sum_squares = sfix(0)\n    for i in range(n):\n        diff = y_test[i] - mean\n        total_sum_squares = total_sum_squares + diff * diff\n        diff_res = y_test[i] - y_hat[i]\n        residual_sum_squares = residual_sum_squares + diff_res * diff_res\n        \n    return sfix(1) - residual_sum_squares / total_sum_squares\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_arcsin", "response_0": "from Compiler.types import sfix\n\n# Helper function to approximate arcsine for sfix numbers.\n# The Taylor series expansion used is:\n# arcsin(x) \u2248 x + (x^3)/6 + (3*x^5)/40 + (5*x^7)/112,\n# which is reasonably accurate for |x| <= 1.\ndef arcsin_approx(x):\n    return x + (x * x * x) / 6 + (3 * (x ** 5)) / 40 + (5 * (x ** 7)) / 112\n\n# Function that computes the arcsine element-wise on an array of sfix numbers.\ndef compute_arcsin(array):\n    # 'array' is expected to be a list of sfix numbers.\n    # The function returns a list where each entry is the approximate arcsine of the corresponding input.\n    return [arcsin_approx(x) for x in array]\n", "response_1": "from Compiler.library import sqrt, atan    # Import secure sqrt and atan routines\nfrom Compiler.types import sfix            # Use secret fixed-point numbers\n\ndef compute_arcsin(array):\n    # Compute the arcsin of each element as: atan(x/\u221a(1 \u2212 x*x))\n    res = []\n    for x in array:\n        # Compute the square root of (1 - x*x)\n        denominator = sqrt(1 - x * x)\n        # Compute the inverse sine using the identity\n        tmp = atan(x / denominator)\n        res.append(tmp)\n    return res\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_true_divide2", "response_0": "from Compiler.types import sfix\n\ndef true_divide(arrayA, arrayB):\n    # assume arrayA and arrayB are lists of sfix numbers\n    res = [a / b for a, b in zip(arrayA, arrayB)]\n    return res\n", "response_1": "from Compiler.types import sfix\n\ndef true_divide(arrayA, arrayB):\n    \"\"\"\n    Compute the element-wise true division of two 1-D arrays.\n    Both arrayA and arrayB should be lists of sfix values.\n    \"\"\"\n    result = []\n    # Use a loop to compute a/b for each corresponding pair in the arrays.\n    for a, b in zip(arrayA, arrayB):\n        result.append(a / b)\n    return result\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "square_error_loss", "response_0": "def squre_error(y, y_pred):\n    # Assume y and y_pred are lists of sfix numbers.\n    n = len(y)\n    total = sfix(0)\n    for i in range(n):\n        diff = y_pred[i] - y[i]\n        total = total + diff * diff\n    return 0.5 * total\n", "response_1": "def square_error(y, y_pred):\n    # Compute the square error loss: 0.5 * ||y_pred - y||^2\n    res = sfix(0)\n    # Assume y and y_pred are lists with the same length\n    for i in range(len(y)):\n        diff = y_pred[i] - y[i]\n        res += diff * diff\n    return res * sfix(0.5)\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_less", "response_0": "def compute_less(arrayA, arrayB):\n    # This function calculates the element\u2010wise comparison,\n    # i.e. whether arrayA[i] is less than arrayB[i] for each i.\n    less_res = []\n    for a, b in zip(arrayA, arrayB):\n        less_res.append(a < b)\n    return less_res\n", "response_1": "def compute_less(arrayA, arrayB):\n    # Create an empty list to store the results.\n    less_res = []\n    # Iterate over the elements in both arrays and compare element-wise.\n    for i in range(len(arrayA)):\n        # The expression \"arrayA[i] < arrayB[i]\" returns a secret bit (i.e. a sint with value 1 if true, else 0).\n        less_res.append(arrayA[i] < arrayB[i])\n    return less_res\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_cos", "response_0": "from Compiler.library import cos\n\ndef compute_cosine(array):\n    \"\"\"\n    This function calculates the trigonometric cosine element-wise\n    on a list (array) of secure fixed-point numbers (sfix).\n    \"\"\"\n    cos_res = [cos(x) for x in array]\n    return cos_res\n", "response_1": "from Compiler.types import sfix\nfrom Compiler.library import cos\n\ndef compute_cosine(array):\n    # Compute the cosine for each sfix element in the array.\n    cos_res = [cos(x) for x in array]\n    return cos_res\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_sin", "response_0": "from Compiler.math import sin\n\ndef compute_sine(array):\n    # This function computes the sine of each element in the secret fixed-point input list.\n    result = []\n    for a in array:\n        # Use the secure sine operation from Compiler.math\n        result.append(sin(a))\n    return result\n", "response_1": "from Compiler.types import sfix\nfrom Compiler.math import sin\n\ndef compute_sine(array):\n    # Create an empty list to store the sine results element-wise.\n    sin_res = []\n    # For each secret-shared fixed point number in the input list,\n    # compute its sine using the secure version of sine.\n    for element in array:\n        sin_res.append(sin(element))\n    return sin_res\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "update_weights", "response_0": "from Compiler.types import sfix\n\ndef update_weights(m, A, X, Y):\n    # m: a public or secret integer (typically a public int)\n    # A and Y: secret-shared vectors of length m (type: list of sfix)\n    # X: secret-shared matrix (list of lists) where each inner list has m elements.\n    \n    # Compute the difference vector diff = A - Y.\n    diff = [a - y for (a, y) in zip(A, Y)]\n    \n    # Initialize the result vector for dweights.\n    dw = []  \n    \n    # Compute the scaling factor 1/m. Ensure m is cast as sfix if needed.\n    one_over_m = 1 / m\n    \n    # For each feature (each row of X),\n    # compute the dot product between the feature (row) and the error vector diff,\n    # then scale by 1/m.\n    for i in range(len(X)):\n        s = sfix(0)\n        for j in range(len(diff)):\n            s = s + X[i][j] * diff[j]\n        dw.append(one_over_m * s)\n    \n    return dw\n", "response_1": "def update_weights(m, A, X, Y):\n    # Compute the difference between vectors A and Y.\n    diff = [a - y for a, y in zip(A, Y)]\n    \n    # Compute the dot product of matrix X and vector diff.\n    # That is, for each row in X, compute the sum of products with the corresponding element in diff.\n    product = []\n    for row in X:\n        s = 0\n        for x, d in zip(row, diff):\n            s = s + x * d\n        product.append(s)\n    \n    # Multiply the result by 1/m to finish the weighted update.\n    dw = [(1 / m) * s for s in product]\n    return dw\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "toy_layer", "response_0": "from Compiler.types import sfix\n\n# Sigmoid activation function: 1/(1+exp(-x))\ndef sigmoid(x):\n    return 1 / (1 + sfix.exp(-x))\n\n# Helper: compute dot product of a vector and a matrix.\n# Here, vec is a list of sfix values, and mat is a 2D list where the number of rows equals the length of vec.\ndef dot_product(vec, mat):\n    # Assume mat dimensions: [len(vec)][output_length]\n    out_length = len(mat[0])\n    res = [sfix(0)] * out_length\n    for j in range(out_length):\n        temp = sfix(0)\n        for i in range(len(vec)):\n            temp += vec[i] * mat[i][j]\n        res[j] = temp\n    return res\n\n# Function that computes a two-layer (toy) neural network.\n# Assume:\n# - input_data is a vector (list) of sfix values.\n# - weights is a list of two matrices:\n#       weights[0]: shape [input_size][hidden_size]\n#       weights[1]: shape [hidden_size][output_size]\n# - biases is a list of two vectors:\n#       biases[0]: length hidden_size\n#       biases[1]: length output_size\ndef toy_layer(input_data, weights, biases):\n    # First layer computation: layer1_input = input_data dot weights[0] + biases[0]\n    layer1_input = dot_product(input_data, weights[0])\n    for i in range(len(layer1_input)):\n        layer1_input[i] += biases[0][i]\n    \n    # Apply the sigmoid function element-wise on the first layer\n    layer1_output = [sigmoid(x) for x in layer1_input]\n    \n    # Second layer computation: layer2_input = layer1_output dot weights[1] + biases[1]\n    layer2_input = dot_product(layer1_output, weights[1])\n    for i in range(len(layer2_input)):\n        layer2_input[i] += biases[1][i]\n    \n    # Apply the sigmoid function element-wise on the second layer\n    layer2_output = [sigmoid(x) for x in layer2_input]\n    return layer2_output\n", "response_1": "from Compiler.types import sfix\n\n# Compute the exponential for sfix values.\n# MP-SPDZ may offer an intrinsic exp method on sfix,\n# here we assume that operator overloading allows (-x).exp()\ndef sigmoid(x):\n    return sfix(1) / (sfix(1) + (-x).exp())\n\n# Helper function to compute the dot product of a vector and a matrix.\ndef dot(vector, matrix):\n    # Assume matrix is a list of lists in which the outer list\n    # corresponds to the rows, and each row has several columns.\n    # In this context, 'vector' is multiplied as a row vector.\n    mcols = len(matrix[0])\n    result = [sfix(0) for _ in range(mcols)]\n    for j in range(mcols):\n        # Compute the j-th entry of the output vector.\n        for i in range(len(vector)):\n            result[j] += vector[i] * matrix[i][j]\n    return result\n\n# Element-wise addition of two vectors.\ndef vector_add(vec1, vec2):\n    return [vec1[i] + vec2[i] for i in range(len(vec1))]\n\n# Implementation of the two-layer toy network.\ndef toy_layer(input_data, weights, biases):\n    # weights should be a list of two matrices and biases a list of two vectors.\n    # Compute first layer: layer1_input = input_data * weights[0] + biases[0]\n    layer1_input = vector_add(dot(input_data, weights[0]), biases[0])\n    \n    # Apply sigmoid element-wise.\n    layer1_output = [sigmoid(val) for val in layer1_input]\n    \n    # Compute second layer: layer2_input = layer1_output * weights[1] + biases[1]\n    layer2_input = vector_add(dot(layer1_output, weights[1]), biases[1])\n    \n    # Apply sigmoid element-wise.\n    layer2_output = [sigmoid(val) for val in layer2_input]\n    \n    return layer2_output\n", "model_name": "azure-openai-o3-mini"}
