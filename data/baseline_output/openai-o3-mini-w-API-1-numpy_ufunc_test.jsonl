{"test_name": "cross_entropy_loss", "response_0": "from Compiler.types import sfix\nfrom Compiler.math import mpc_math\n\ndef cross_entropy(y):\n    # Compute the cross-entropy loss.\n    loss = sfix(0)\n    n = len(y)\n    for i in range(n):\n        loss += y[i] * mpc_math.log_fx(y[i])\n    return -loss\n", "response_1": "from Compiler.types import sfix\nimport mpc_math\n\ndef cross_entropy(y):\n    # y is expected to be an array (or list) of sfix numbers.\n    total = sfix(0)\n    n = len(y)\n    for i in range(n):\n        # Compute natural logarithm of y[i] by specifying the base e.\n        # Here, mpc_math.log_fx(x, b) computes log base b of x. We set b = e.\n        log_val = mpc_math.log_fx(y[i], sfix(2.7182818))\n        total = total + y[i] * log_val\n    return -total\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_square_sqrt", "response_0": "from Compiler.types import sfix\nimport Compiler.mpc_math as mpc_math\n\ndef compute_RMSD(array):\n    # Number of elements (assumed to be public)\n    n = len(array)\n    total = sfix(0)\n    # Sum all elements in the array\n    for x in array:\n        total = total + x\n    mean = total / n\n\n    square_sum = sfix(0)\n    # Compute the sum of squared deviations\n    for x in array:\n        deviation = x - mean\n        square_sum = square_sum + deviation * deviation\n    square_mean = square_sum / n\n\n    # Compute and return the square root of the mean square deviation\n    rmsd = mpc_math.sqrt(square_mean)\n    return rmsd\n", "response_1": "from Compiler.types import sfix\nimport mpc_math\n\ndef compute_RMSD(array):\n    # Compute the mean of the elements in the array\n    n = len(array)\n    total = array[0]\n    for i in range(1, n):\n        total = total + array[i]\n    mean = total / sfix(n)\n    \n    # Compute the sum of squared deviations from the mean\n    total_sq = sfix(0)\n    for i in range(n):\n        deviation = array[i] - mean\n        total_sq = total_sq + deviation * deviation\n    \n    # Compute the mean of the squares and take its square root\n    square_mean = total_sq / sfix(n)\n    rmsd = mpc_math.sqrt(square_mean)\n    return rmsd\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "logsumexp", "response_0": "from Compiler.types import sfix\nimport mpc_math\n\ndef logsumexp(log_probs):\n    # Compute the maximum value in log_probs securely.\n    max_val = log_probs[0]\n    for p in log_probs[1:]:\n        # The comparison \"p > max_val\" returns a secret bit.\n        # Use it to select the maximum securely.\n        max_val = (p > max_val).if_else(p, max_val)\n    # Subtract the maximum from each log probability.\n    ds = [p - max_val for p in log_probs]\n    # Compute exponentials: exp(d) = e^d, where e is approximated by 2.718281828459045.\n    exp_vals = [mpc_math.pow_fx(2.718281828459045, d) for d in ds]\n    # Sum up the computed exponentials.\n    exp_sum = exp_vals[0]\n    for v in exp_vals[1:]:\n        exp_sum = exp_sum + v\n    # Compute the natural logarithm of the sum and add back the maximum.\n    return max_val + mpc_math.log_fx(exp_sum, 2.718281828459045)\n", "response_1": "from Compiler.types import sfix, Array\nfrom Compiler.library import tree_reduce\nimport mpc_math\n\ndef logsumexp(log_probs):\n    # Compute the maximum element of log_probs using tree_reduce and the max operation.\n    _max = tree_reduce(lambda a, b: a.max(b), log_probs)\n    # Subtract the maximum from each entry (element\u2010wise)\n    ds = log_probs - _max\n    # Constant e for exponentiation\n    e_const = sfix(2.718281828459045)\n    # Compute the sum of exponentials e^(d) for each d in the adjusted list\n    exp_sum = sfix(0)\n    for d in ds:\n        exp_sum += mpc_math.pow_fx(e_const, d)\n    # Compute the natural logarithm of the sum using mpc_math.log_fx,\n    # where the second argument specifies the base (e_const) for natural logarithm.\n    log_exp_sum = mpc_math.log_fx(exp_sum, e_const)\n    # Return the log-sum-exp result\n    return _max + log_exp_sum\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "binary_cross_entropy_loss", "response_0": "from Compiler.types import sfix\nimport mpc_math\n\ndef binary_cross_entropy(y_hat, y):\n    # Assume y_hat and y are sfix Arrays of the same public length.\n    n = len(y_hat)\n    # Clip predicted probabilities: if y_hat == 0 then assign 0.001; if y_hat == 1 then assign 0.999.\n    for i in range(n):\n        # Create secret constants for 0, 0.001, 1, and 0.999.\n        zero   = sfix(0)\n        one    = sfix(1)\n        eps    = sfix(0.001)\n        one_eps = sfix(0.999)\n        # Compute secret bits for equality comparisons.\n        eq_zero = (y_hat[i] == zero)   # returns a secret bit (sbitint)\n        eq_one  = (y_hat[i] == one)\n        # Replace y_hat[i] with 0.001 if it equals 0.\n        new_val = eq_zero.if_else(sfix(0.001), y_hat[i])\n        # Replace new_val with 0.999 if y_hat[i] equals 1.\n        y_hat[i] = eq_one.if_else(sfix(0.999), new_val)\n        \n    # Compute the binary cross-entropy loss.\n    s = sfix(0)\n    for i in range(n):\n        # Compute log base 2 for y_hat[i] and (1 - y_hat[i])\n        log_y_hat     = mpc_math.log_fx(y_hat[i], 2)\n        log_one_minus = mpc_math.log_fx(sfix(1) - y_hat[i], 2)\n        term = y[i] * log_y_hat + (sfix(1) - y[i]) * log_one_minus\n        s += term\n    loss = - s / sfix(n)\n    return loss\n", "response_1": "from Compiler.types import sfix\nfrom Compiler import mpc_math\n\ndef binary_cross_entropy(y_hat, y):\n    n = len(y_hat)\n    total = sfix(0)\n    for i in range(n):\n        # Clip probability predictions to avoid log(0)\n        cond_zero = (y_hat[i] == sfix(0))\n        y_hat[i] = cond_zero.if_else(sfix(0.001), y_hat[i])\n        cond_one = (y_hat[i] == sfix(1))\n        y_hat[i] = cond_one.if_else(sfix(0.999), y_hat[i])\n        # Compute the binary cross-entropy term for the i-th element\n        term = y[i] * mpc_math.log_fx(y_hat[i], 2) + (sfix(1) - y[i]) * mpc_math.log_fx(sfix(1) - y_hat[i], 2)\n        total += term\n    mean = total / sfix(n)\n    loss = sfix(0) - mean\n    return loss\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_less_equal", "response_0": "from Compiler.types import sint\n\ndef compute_less_equal(arrayA, arrayB):\n    # Assuming arrayA and arrayB are sint.Array of the same length.\n    n = len(arrayA)\n    result = sint.Array(n)\n    for i in range(n):\n        # The comparison returns a secret bit.\n        result[i] = arrayA[i] <= arrayB[i]\n    return result\n", "response_1": "from Compiler.types import sint\n\ndef compute_less_equal(arrayA, arrayB):\n    \"\"\"\n    Compute element-wise less than or equal comparison between arrayA and arrayB.\n    This returns a vector of secret bits indicating whether each element of arrayA\n    is less than or equal to the corresponding element in arrayB.\n    \"\"\"\n    less_eq = arrayA <= arrayB\n    return less_eq\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "RMS_prop_step", "response_0": "from Compiler.types import sfix\nimport mpc_math\n\ndef RMS_prop_step(grads, layers):\n    # Constants for fixed-point arithmetic\n    alpha = sfix(0.5)\n    beta = sfix(1.0)\n    one = sfix(1.0)\n    \n    # Initialize s with containers of the same shape as each grad, and assign zeros.\n    s = []\n    for grad in grads:\n        temp = grad.same_shape()\n        temp.assign_all(0)\n        s.append(temp)\n    \n    # Iterate over the gradients and layers to perform the RMS propagation update.\n    for i in range(len(grads)):\n        # Update running average of squared gradients: s[i] = beta*s[i] + (1-beta)*(grad^2)\n        s[i] = beta * s[i] + (one - beta) * (grads[i] * grads[i])\n        \n        # Compute the square root of the running average.\n        sqrt_s = mpc_math.sqrt(s[i])\n        \n        # Compute the scaled gradient: grad = alpha * (grad / sqrt(s[i]))\n        new_grad = alpha * (grads[i] / sqrt_s)\n        \n        # Update the corresponding layer: layer = layer + grad\n        layers[i] = layers[i] + new_grad\n        \n    return layers\n", "response_1": "from Compiler.types import sfix\nimport mpc_math\n\ndef RMS_prop_step(grads, layers):\n    # Use fixed-point constants\n    alpha = sfix(0.5)\n    beta = sfix(1.0)\n    one = sfix(1.0)\n    # Create s as a list of arrays of sfix with the same shape as each grad,\n    # and initialize all entries to 0.\n    s = []\n    for grad in grads:\n        tmp = grad.same_shape()  # get an array with the same shape and type as grad\n        tmp.assign_all(0)\n        s.append(tmp)\n    # For each grad/layer pair, update the running square average and the parameter.\n    for i in range(len(grads)):\n        # Update s[i] element-wise:\n        # s[i] = beta * s[i] + (1-beta) * (grad)**2\n        s[i] = beta * s[i] + (one - beta) * (grads[i] * grads[i])\n        # Compute the adjustment using the square root of s[i]\n        new_grad = alpha * (grads[i] / mpc_math.sqrt(s[i]))\n        # Update the layer element-wise:\n        layers[i] = layers[i] + new_grad\n    return layers\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "entropy", "response_0": "from Compiler.types import sfix\nimport mpc_math\n\ndef entropy(y):\n    # Assume y is a Python list of values (public or computed in clear).\n    # n is the total number of samples.\n    n = len(y)\n    total = sfix(0)\n  \n    # Compute the unique set of values in y.\n    unique_vals = []\n    for val in y:\n        if val not in unique_vals:\n            unique_vals.append(val)\n  \n    # For each unique value, count its occurrences and add its contribution.\n    for val in unique_vals:\n        v = 0\n        for a in y:\n            # Comparison is done in the clear.\n            if a == val:\n                v += 1\n        # Convert counts to secret fixed-point numbers.\n        p = sfix(v) / sfix(n)\n        # Compute contribution: - p * log2(p)\n        total = total + ( - p * mpc_math.log_fx(p, sfix(2)) )\n  \n    return total\n", "response_1": "from Compiler.types import cfix\nimport mpc_math\n\ndef entropy(y):\n    # y is assumed to be a public list (or Array converted to a Python list) of integers\n    n = len(y)\n    sum_val = cfix(0)\n    # Get unique elements from y using Python's set\n    unique_vals = set(y)\n    for i in unique_vals:\n        # Count the occurrences of i in y\n        v = 0\n        for yi in y:\n            if yi == i:\n                v += 1\n        # Compute the probability, as a clear fixed\u2010point number\n        prob = cfix(v) / cfix(n)\n        # Only update the entropy if prob is nonzero (v>0)\n        if v:\n            sum_val += -(prob * mpc_math.log_fx(prob, 2))\n    return sum_val\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_exp", "response_0": "from Compiler.types import sfix\nimport mpc_math\n\ndef compute_softmax(array):\n    # Define the constant e as an sfix constant (approximation of Euler's number)\n    e = sfix(2.718281828459045)\n    \n    # Compute the exponentials elementwise using mpc_math.pow_fx for exponentiation.\n    # Here, exp_i = e^(array[i])\n    n = len(array)\n    exp_array = [None] * n\n    for i in range(n):\n        exp_array[i] = mpc_math.pow_fx(e, array[i])\n    \n    # Compute the summation of exponentials.\n    summation = sfix(0)\n    for i in range(n):\n        summation += exp_array[i]\n    \n    # Compute softmax values by dividing each exponential by the summation.\n    softmax = [None] * n\n    for i in range(n):\n        softmax[i] = exp_array[i] / summation\n    \n    return softmax\n", "response_1": "from Compiler.types import sfix, Array\nimport mpc_math\n\ndef compute_softmax(array):\n    # Assume 'array' is an Array of sfix values (1-D vector)\n    n = len(array)\n    exp_array = sfix.Array(n)\n    # Compute the exponentials of each element: exp(x) = e^x.\n    # Here we use mpc_math.pow_fx to compute e^x for each x.\n    const_e = sfix(2.718281828459045)\n    for i in range(n):\n        exp_array[i] = mpc_math.pow_fx(const_e, array[i])\n    # Compute the summation of the exponentials.\n    summation = sfix(0)\n    for i in range(n):\n        summation += exp_array[i]\n    # Compute the softmax: each entry divided by the summation.\n    softmax = sfix.Array(n)\n    for i in range(n):\n        softmax[i] = exp_array[i] / summation\n    return softmax\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "tanh", "response_0": "from Compiler.library import mpc_math\n\nclass Tanh:\n    def fn(self, z):\n        # Computes the tanh function on each element of z using MP-SPDZ's tanh implementation.\n        return mpc_math.tanh(z)\n\n    def grad(self, x):\n        # Computes the derivative of tanh on each element of x: 1 - tanh(x)**2\n        return 1 - mpc_math.tanh(x)**2\n", "response_1": "from Compiler.types import sfix\nimport mpc_math\n\nclass Tanh:\n    def fn(self, z):\n        # Compute the hyperbolic tangent element-wise on input z.\n        return mpc_math.tanh(z)\n\n    def grad(self, x):\n        # Compute the derivative: 1 - tanh(x)^2.\n        return sfix(1) - (mpc_math.tanh(x)) ** 2\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_tan", "response_0": "from Compiler.mpc_math import tan\n\ndef compute_tan(arr):\n    # Calculate trigonometric tangent element-wise for an array of sfix elements.\n    tan_res = [tan(x) for x in arr]\n    return tan_res\n", "response_1": "from Compiler.types import sfix\nimport mpc_math\n\ndef compute_tan(arr):\n    # Compute the tangent element-wise for a vector of sfix numbers.\n    tan_res = [mpc_math.tan(x) for x in arr]\n    return tan_res\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_greater", "response_0": "from Compiler.types import sint\n\ndef compute_greater(arrayA, arrayB):\n    # Compute the element\u2010wise comparison: whether each element in arrayA is greater than the corresponding element in arrayB.\n    greater_res = arrayA > arrayB\n    return greater_res\n", "response_1": "from Compiler.types import sint\n\ndef compute_greater(arrayA, arrayB):\n    # Compute the element-wise comparison: return 1 if an element in arrayA is greater than the corresponding element in arrayB, else 0.\n    greater_res = arrayA > arrayB\n    return greater_res\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_maximum", "response_0": "from Compiler.types import sint\n\ndef compute_maximum(arrayA, arrayB):\n    # Assume arrayA and arrayB are sint.Array objects of the same length\n    n = len(arrayA)\n    result = sint.Array(n)\n    for i in range(n):\n        # Use the element-wise 'max' method for secret integers\n        result[i] = arrayA[i].max(arrayB[i])\n    return result\n", "response_1": "from Compiler.types import sint\n\ndef compute_maximum(arrayA, arrayB):\n    n = len(arrayA)\n    result = sint.Array(n)\n    for i in range(n):\n        result[i] = arrayA[i].max(arrayB[i])\n    return result\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_log2", "response_0": "from Compiler.library import mpc_math\n\ndef compute_log2(array):\n    \"\"\"\n    This function calculates the base-2 logarithm of each element in the input array.\n    \"\"\"\n    result = mpc_math.log_fx(array, 2)\n    return result\n", "response_1": "from Compiler.library import mpc_math\nfrom Compiler.types import sfix\n\ndef compute_log2(array):\n    # Assume 'array' is an instance of sfix.Array\n    result = array.same_shape()\n    for i in range(len(array)):\n        result[i] = mpc_math.log_fx(array[i], 2)\n    return result\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_absolute", "response_0": "from Compiler.types import sint  # or use cint or sfix depending on your application\n\ndef obtain_absolute(array):\n    # This function computes the absolute value for each element of an MP-SPDZ Array.\n    result = array.same_shape()\n    for i in range(len(array)):\n        result[i] = abs(array[i])\n    return result\n", "response_1": "def obtain_absolute(array):\n    \"\"\"\n    This function computes the absolute values in an MP-SPDZ array.\n    It returns a new array where each entry is the absolute value of the\n    corresponding entry in the input array.\n    \"\"\"\n    res = array.same_shape()\n    for i in range(len(array)):\n        res[i] = abs(array[i])\n    return res\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_arctan", "response_0": "from Compiler.types import sfix\nimport mpc_math\n\ndef compute_arctan(array):\n    \"\"\"\n    This function calculates the trigonometric inverse tangent element-wise.\n    \"\"\"\n    # Assuming array is a list or vector of sfix values.\n    arctan_res = [mpc_math.atan(x) for x in array]\n    return arctan_res\n", "response_1": "from Compiler.types import sfix\nimport mpc_math\n\ndef compute_arctan(array):\n    # Assume \"array\" is an sfix.Array of secret fixed-point numbers\n    n = len(array)\n    result = sfix.Array(n)\n    for i in range(n):\n        result[i] = mpc_math.atan(array[i])\n    return result\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_log", "response_0": "from Compiler.types import sfix, Array\nimport Compiler.math as mpc_math\n\ndef compute_log(arr):\n    # Create an Array to hold the logarithm results\n    n = len(arr)\n    res = sfix.Array(n)\n    # Define the natural constant e as a fixed-point number (approximation)\n    e = sfix(2.718281828459045)\n    for i in range(n):\n        res[i] = mpc_math.log_fx(arr[i], e)\n    return res\n", "response_1": "from Compiler.types import sfix\nimport mpc_math\n\ndef compute_log(array):\n    # Compute natural logarithm elementwise (log base e)\n    n = len(array)\n    result = [None] * n\n    # Create a secret fixed-point representation of Euler's constant e\n    e_const = sfix(2.718281828459045)\n    for i in range(n):\n        result[i] = mpc_math.log_fx(array[i], e_const)\n    return result\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_not_equal", "response_0": "from Compiler.types import sint\n\ndef compute_not_equal(arrayA, arrayB):\n    # Compute element-wise not-equal comparison returning secret bits.\n    neq = [a != b for a, b in zip(arrayA, arrayB)]\n    return neq\n", "response_1": "def compute_not_equal(arrayA, arrayB):\n    # Compute element-wise not-equal by comparing corresponding entries.\n    neq = [a != b for a, b in zip(arrayA, arrayB)]\n    return neq\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_equal", "response_0": "from Compiler.types import sint\n\ndef compute_equal(arrayA, arrayB):\n    # Element-wise equality comparison, returns an array of secret bits\n    eq = arrayA == arrayB\n    return eq\n", "response_1": "from Compiler.types import sint\n\ndef compute_equal(arrayA, arrayB):\n    # Compute element-wise equality between arrayA and arrayB.\n    # The equality operator (==) is defined element-wise for MP-SPDZ container types.\n    eq = arrayA == arrayB\n    return eq\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_true_divide", "response_0": "from Compiler.types import sfix\n\ndef true_divide(arrayA, arrayB):\n    # Element-wise true division between two arrays of sfix values.\n    # Assuming that arrayA and arrayB are sfix.Array instances of equal length.\n    n = len(arrayA)\n    out = sfix.Array(n)\n    for i in range(n):\n        out[i] = arrayA[i] / arrayB[i]\n    return out\n", "response_1": "from Compiler.types import sfix\n\ndef true_divide(arrayA, arrayB):\n    # Perform element\u2010wise division of two sfix arrays.\n    result = arrayA / arrayB\n    return result\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_greater_equal", "response_0": "from Compiler.types import sint\n\ndef compute_greater_equal(arrayA, arrayB):\n    # Perform element-wise greater-than-or-equal comparison.\n    # Note: For secret integers, the comparison produces secret bits (sintbit).\n    greater_eq = arrayA >= arrayB\n    return greater_eq\n", "response_1": "from Compiler.types import sint\n\ndef compute_greater_equal(arrayA, arrayB):\n    # Assume arrayA and arrayB are sequences (e.g. lists or sint.Array slice)\n    n = len(arrayA)\n    result = [None] * n\n    for i in range(n):\n        result[i] = arrayA[i] >= arrayB[i]\n    return result\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_negative", "response_0": "from Compiler.types import sint\n\ndef negative(arrayA):\n    # This function returns a copy of the input array with all its elements negated.\n    negated_array = -arrayA\n    return negated_array\n", "response_1": "from Compiler.types import sint\n\ndef negative(arrayA):\n    # Returns a copy of arrayA with all elements negated.\n    neg_array = -arrayA\n    return neg_array\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_power", "response_0": "from Compiler.types import sfix\nimport mpc_math\n\ndef power(arrayA, arrayB):\n    # Assumes arrayA and arrayB are sfix.Array types of equal length\n    n = len(arrayA)\n    result = sfix.Array(n)\n    for i in range(n):\n        result[i] = mpc_math.pow_fx(arrayA[i], arrayB[i])\n    return result\n", "response_1": "from Compiler.types import sfix\nimport mpc_math\n\ndef power(arrayA, arrayB):\n    # Compute element-wise power using mpc_math.pow_fx for secret fixed-point numbers\n    n = len(arrayA)\n    result = sfix.Array(n)\n    for i in range(n):\n        result[i] = mpc_math.pow_fx(arrayA[i], arrayB[i])\n    return result\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_exp2", "response_0": "from Compiler.library import mpc_math\nfrom Compiler.types import sfix\n\ndef compute_exp2(array):\n    \"\"\"\n    This function calculates 2^p for all p in the input secret fixed-point array.\n    \"\"\"\n    result = []\n    for p in array:\n        # Compute 2**p using MP-SPDZ's power function for sfix operands.\n        result.append(mpc_math.pow_fx(2, p))\n    return result\n", "response_1": "from Compiler.types import sfix, Array\nimport mpc_math\n\ndef compute_exp2(a):\n    # a is assumed to be an Array of sfix numbers\n    n = len(a)\n    res = Array(n, sfix)\n    for i in range(n):\n        res[i] = mpc_math.pow_fx(sfix(2), a[i])\n    return res\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "cross_entropy_loss_class", "response_0": "from Compiler.types import sfix\nimport mpc_math\n\nclass CrossEntropy:\n    def loss(self, y, y_pred):\n        # Compute the cross entropy loss as -sum(y * log_2(y_pred))\n        cross_entropy = sfix(0)\n        n = len(y)\n        for i in range(n):\n            # Use mpc_math.log_fx for logarithm with base 2\n            cross_entropy += y[i] * mpc_math.log_fx(y_pred[i], 2)\n        return -cross_entropy\n\n    def grad(self, y, y_pred):\n        # Compute the gradient: (y_pred - y) / n\n        n = len(y)\n        grad = y_pred - y\n        grad = grad / sfix(n)\n        return grad\n", "response_1": "from Compiler.types import sfix\nfrom Compiler.library import mpc_math\n\nclass CrossEntropy:\n    def loss(self, y, y_pred):\n        # Compute the cross-entropy loss: -sum(y * log2(y_pred))\n        n = len(y)\n        ce = sfix(0)\n        for i in range(n):\n            # Compute the logarithm in base 2 using mpc_math.log_fx (first argument is the base)\n            ce += y[i] * mpc_math.log_fx(2, y_pred[i])\n        return -ce\n\n    def grad(self, y, y_pred):\n        # Compute the gradient: (y_pred - y) / n\n        n = len(y)\n        grad = [None] * n\n        for i in range(n):\n            grad[i] = (y_pred[i] - y[i]) / n\n        return grad\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_arccos", "response_0": "from Compiler.library import mpc_math\n\ndef compute_arccos(array):\n    \"\"\"\n    This function calculates the trigonometric inverse cosine, element-wise,\n    using mpc_math.acos on each element of the input array.\n    \"\"\"\n    result = [mpc_math.acos(x) for x in array]\n    return result\n", "response_1": "from Compiler.types import sfix\nimport mpc_math\n\ndef compute_arccos(a):\n    n = len(a)\n    res = sfix.Array(n)\n    for i in range(n):\n        res[i] = mpc_math.acos(a[i])\n    return res\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "r2_score", "response_0": "from Compiler.types import sfix\n\ndef r2_score(y_hat, y_test):\n    # determine number of elements\n    n = len(y_test)\n    \n    # Compute mean of y_test.\n    sum_y = sfix(0)\n    for i in range(n):\n        sum_y += y_test[i]\n    y_mean = sum_y / n\n    \n    # Compute total sum of squares and residual sum of squares.\n    total_sum_squares = sfix(0)\n    residual_sum_squares = sfix(0)\n    for i in range(n):\n        diff1 = y_test[i] - y_mean\n        diff2 = y_test[i] - y_hat[i]\n        total_sum_squares += diff1 * diff1\n        residual_sum_squares += diff2 * diff2\n    \n    # Calculate R2 score.\n    return sfix(1) - residual_sum_squares / total_sum_squares\n", "response_1": "from Compiler.types import sfix\n\ndef r2_score(y_hat, y_test):\n    n = len(y_test)\n    mean_val = sfix(0)\n    for i in range(n):\n        mean_val += y_test[i]\n    mean_val = mean_val / n\n\n    total_sum_squares = sfix(0)\n    residual_sum_squares = sfix(0)\n    for i in range(n):\n        diff_mean = y_test[i] - mean_val\n        total_sum_squares += diff_mean * diff_mean\n        diff_hat = y_test[i] - y_hat[i]\n        residual_sum_squares += diff_hat * diff_hat\n\n    return 1 - residual_sum_squares / total_sum_squares\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_arcsin", "response_0": "from Compiler.types import sfix\nimport mpc_math\n\ndef compute_arcsin(arr):\n    n = len(arr)\n    res = sfix.Array(n)\n    for i in range(n):\n        res[i] = mpc_math.asin(arr[i])\n    return res\n", "response_1": "from Compiler.library import mpc_math\nfrom Compiler.types import sfix, Array\n\ndef compute_arcsin(x):\n    n = len(x)\n    res = sfix.Array(n)\n    for i in range(n):\n        res[i] = mpc_math.asin(x[i])\n    return res\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_true_divide2", "response_0": "from Compiler.types import sfix\n\ndef true_divide(arrayA, arrayB):\n    # Assume arrayA and arrayB are MP-SPDZ sfix arrays or lists of sfix numbers.\n    n = len(arrayA)\n    res = sfix.Array(n)\n    for i in range(n):\n        res[i] = arrayA[i] / arrayB[i]\n    return res\n", "response_1": "from Compiler.types import cfix\n\ndef true_divide(arrayA, arrayB):\n    n = len(arrayA)\n    res = cfix.Array(n)\n    for i in range(n):\n        res[i] = arrayA[i] / arrayB[i]\n    return res\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "square_error_loss", "response_0": "from Compiler.library import tree_reduce\n\ndef squre_error(y, y_pred):\n    # Compute element-wise difference and square it\n    diff = y_pred - y\n    sq_diff = diff * diff\n    # Sum over all elements of the squared differences\n    sum_sq = tree_reduce(lambda a, b: a + b, sq_diff)\n    # Return half of the sum, corresponding to 0.5 * ||y_pred-y||^2\n    return 0.5 * sum_sq\n", "response_1": "from Compiler.types import sfix\n\ndef squre_error(y, y_pred):\n    # Compute the difference between prediction and target.\n    diff = y_pred - y\n    loss = sfix(0)\n    n = len(diff)\n    for i in range(n):\n        loss += diff[i] * diff[i]\n    return loss * 0.5\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_less", "response_0": "from Compiler.types import sfix\n\ndef compute_less(arrayA, arrayB):\n    \"\"\"\n    Compute the element-wise comparison of whether arrayA is less than arrayB.\n    Returns a vector of secret bits (sbitint) representing the comparison result.\n    \"\"\"\n    # The '<' operator performs element-wise comparison for secret types.\n    less_res = arrayA < arrayB\n    return less_res\n", "response_1": "from Compiler.types import sint\n\ndef compute_less(arrayA, arrayB):\n    # Perform an element-wise less-than comparison.\n    less_res = arrayA < arrayB\n    return less_res\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_cos", "response_0": "from Compiler.types import sfix, Array\nimport mpc_math\n\ndef compute_cosine(arr):\n    # Assume arr is an Array of sfix numbers\n    n = len(arr)\n    cos_arr = sfix.Array(n)\n    for i in range(n):\n        cos_arr[i] = mpc_math.cos(arr[i])\n    return cos_arr\n", "response_1": "from Compiler.types import sfix\nimport mpc_math\n\ndef compute_cosine(array):\n    # Compute the cosine of each element in the array (assumed to be of type sfix or a compatible container)\n    cos_res = [mpc_math.cos(x) for x in array]\n    return cos_res\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "np_ufunc_sin", "response_0": "from Compiler.types import sfix, Array\nfrom Compiler import mpc_math\n\ndef compute_sine(arr):\n    n = len(arr)\n    sin_res = Array(n, sfix)\n    for i in range(n):\n        sin_res[i] = mpc_math.sin(arr[i])\n    return sin_res\n", "response_1": "from Compiler.library import mpc_math\n\ndef compute_sine(array):\n    # Compute the sine of each element in the array using the built-in MP-SPDZ trigonometric function.\n    sin_res = mpc_math.sin(array)\n    return sin_res\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "update_weights", "response_0": "from Compiler.types import sfix\n\ndef update_weights(m, A, X, Y):\n    # Compute the difference between A and Y element-wise\n    diff = A - Y\n    # Compute the dot product of X and diff; here we assume that X is an\n    # sfix Array/Matrix that implements the dot() method.\n    dot_val = X.dot(diff)\n    # Compute the scaling factor (1/m) as an sfix number.\n    factor = sfix(1) / m\n    # Multiply the factor with the dot product to obtain the weight update.\n    dw = factor * dot_val\n    return dw\n", "response_1": "from Compiler.types import sfix\n\ndef update_weights(m, A, X, Y):\n    # Compute the element-wise difference (A - Y)\n    diff = A - Y\n    n = len(diff)\n    dot = sfix(0)\n    for i in range(n):\n        dot += X[i] * diff[i]\n    # Multiply by 1/m (here m is assumed to be public)\n    dw = (sfix(1) / m) * dot\n    return dw\n", "model_name": "azure-openai-o3-mini"}
{"test_name": "toy_layer", "response_0": "from Compiler.types import sfix, Array, Matrix\nfrom Compiler.library import mpc_math\n\ndef sigmoid(x):\n    # Compute the sigmoid function as: 1 / (1 + exp(-x))\n    return 1 / (1 + mpc_math.exp(-x))\n\ndef toy_layer(input_data, weights, biases):\n    # Compute first layer: layer1 = sigmoid(dot(input_data, weights[0]) + biases[0])\n    layer1_input = input_data.dot(weights[0]) + biases[0]\n    n = len(layer1_input)\n    layer1_output = sfix.Array(n)\n    for i in range(n):\n        layer1_output[i] = sigmoid(layer1_input[i])\n    \n    # Compute second layer: output = sigmoid(dot(layer1_output, weights[1]) + biases[1])\n    layer2_input = layer1_output.dot(weights[1]) + biases[1]\n    m = len(layer2_input)\n    layer2_output = sfix.Array(m)\n    for i in range(m):\n        layer2_output[i] = sigmoid(layer2_input[i])\n    \n    return layer2_output\n", "response_1": "from Compiler.types import sfix\nimport mpc_math\n\ndef sigmoid(x):\n    e_const = sfix(2.718281828459045)\n    return sfix(1) / (sfix(1) + mpc_math.pow_fx(e_const, -x))\n\ndef toy_layer(input_data, weights, biases):\n    # Compute first layer: input_data is a vector, weights[0] is a matrix and biases[0] is a vector.\n    layer1_input = input_data.dot(weights[0]) + biases[0]\n    layer1_output = sigmoid(layer1_input)\n    \n    # Compute second layer: layer1_output is a vector, weights[1] is a matrix and biases[1] is a vector.\n    layer2_input = layer1_output.dot(weights[1]) + biases[1]\n    layer2_output = sigmoid(layer2_input)\n    \n    return layer2_output\n", "model_name": "azure-openai-o3-mini"}
